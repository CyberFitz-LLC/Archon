From 2bba90e72d6f1ae5df238dbab324d73c12ce99a3 Mon Sep 17 00:00:00 2001
From: John Fitzpatrick <john@cyberfitz.org>
Date: Fri, 15 Aug 2025 22:45:48 -0700
Subject: [PATCH 33/38] feat: Implement database persistence and intelligent
 load balancing for Ollama instances
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This comprehensive implementation replaces localStorage-based Ollama configuration
with robust database persistence and intelligent load balancing capabilities.

ðŸš€ Backend Implementation:
- credential_service.py: Added comprehensive Ollama instance management methods
  - get_ollama_instances(): Retrieve instances from database with validation
  - set_ollama_instances(): Store instances with structure validation
  - add_ollama_instance(): Add new instances with duplicate checking
  - remove_ollama_instance(): Remove instances with primary failover
  - update_ollama_instance(): Update instance properties
  - get_primary_ollama_instance(): Get primary instance for fallback
  - get_healthy_ollama_instances(): Get healthy instances for load balancing

- llm_provider_service.py: Intelligent load balancing algorithm
  - get_best_ollama_instance(): Weighted selection based on health and performance
  - Health factor: Prefers instances with response time < 1000ms
  - Model availability factor: Prefers instances with more models
  - Automatic failover to primary instance on errors

- provider_config_api.py: Database-backed API endpoints
  - GET /api/provider-config/current: Retrieve current configuration
  - POST /api/provider-config/ollama/add-instance: Add new instances
  - DELETE /api/provider-config/ollama/remove-instance/{id}: Remove instances
  - GET /api/provider-config/ollama/load-balancing-status: Monitor load balancing

ðŸŽ¨ Frontend Implementation:
- credentialsService.ts: Database operations for Ollama instances
  - getOllamaInstances(): Fetch instances from database
  - setOllamaInstances(): Save instances to database
  - addOllamaInstance(): Add new instance via API
  - removeOllamaInstance(): Remove instance via API
  - updateOllamaInstance(): Update instance properties
  - migrateOllamaFromLocalStorage(): Seamless migration support

- OllamaConfigurationPanel.tsx: Complete UI migration
  - Database-first operation with localStorage fallback
  - Automatic migration from localStorage to database
  - Real-time health monitoring and status display
  - Load balancing configuration and weight management
  - Comprehensive error handling and user feedback

âœ¨ Key Features:
- Cross-computer synchronization through database storage
- Intelligent load distribution with weighted random selection
- Automatic health monitoring and failover capabilities
- Seamless migration from localStorage to database
- Real-time status updates and configuration management
- Robust error handling with fallback mechanisms
- Production-ready validation and data integrity checks

ðŸ§ª Tested and Verified:
- Database persistence operations (CRUD)
- Load balancing algorithm with multiple instances
- Migration from localStorage to database
- API endpoint functionality and error handling
- Frontend UI integration and real-time updates

ðŸ¤– Generated with Claude Code (https://claude.ai/code)

Co-Authored-By: Claude <noreply@anthropic.com>
---
 .../settings/OllamaConfigurationPanel.tsx     | 213 +++++----
 .../src/services/credentialsService.ts        | 198 +++++++++
 .../server/api_routes/provider_config_api.py  | 127 +++---
 .../src/server/services/credential_service.py | 406 ++++++++++++++++++
 .../server/services/llm_provider_service.py   |  94 +++-
 5 files changed, 875 insertions(+), 163 deletions(-)

diff --git a/archon-ui-main/src/components/settings/OllamaConfigurationPanel.tsx b/archon-ui-main/src/components/settings/OllamaConfigurationPanel.tsx
index f8a6dda..bf8aedd 100644
--- a/archon-ui-main/src/components/settings/OllamaConfigurationPanel.tsx
+++ b/archon-ui-main/src/components/settings/OllamaConfigurationPanel.tsx
@@ -5,19 +5,7 @@ import { Input } from '../ui/Input';
 import { Badge } from '../ui/Badge';
 import { useToast } from '../../contexts/ToastContext';
 import { cn } from '../../lib/utils';
-
-interface OllamaInstance {
-  id: string;
-  name: string;
-  baseUrl: string;
-  isEnabled: boolean;
-  isPrimary: boolean;
-  loadBalancingWeight: number;
-  isHealthy?: boolean;
-  responseTimeMs?: number;
-  modelsAvailable?: number;
-  lastHealthCheck?: string;
-}
+import { credentialsService, OllamaInstance } from '../../services/credentialsService';
 
 interface OllamaConfigurationPanelProps {
   isVisible: boolean;
@@ -37,45 +25,69 @@ const OllamaConfigurationPanel: React.FC<OllamaConfigurationPanelProps> = ({
   onConfigChange,
   className = ''
 }) => {
-  // Load instances from localStorage or use default
-  const loadInstances = (): OllamaInstance[] => {
-    try {
-      const saved = localStorage.getItem('ollama-instances');
-      if (saved) {
-        return JSON.parse(saved);
-      }
-    } catch (error) {
-      console.error('Failed to load Ollama instances from localStorage:', error);
-    }
-    
-    // Default instances
-    return [
-      {
-        id: 'primary',
-        name: 'Primary Ollama Instance',
-        baseUrl: 'http://localhost:11434',
-        isEnabled: true,
-        isPrimary: true,
-        loadBalancingWeight: 100
-      }
-    ];
-  };
-
-  const [instances, setInstances] = useState<OllamaInstance[]>(loadInstances());
+  const [instances, setInstances] = useState<OllamaInstance[]>([]);
+  const [loading, setLoading] = useState(true);
   const [testingConnections, setTestingConnections] = useState<Set<string>>(new Set());
   const [newInstanceUrl, setNewInstanceUrl] = useState('');
   const [newInstanceName, setNewInstanceName] = useState('');
   const [showAddInstance, setShowAddInstance] = useState(false);
   const { showToast } = useToast();
 
-  // Save instances to localStorage
-  const saveInstances = (newInstances: OllamaInstance[]) => {
+  // Load instances from database
+  const loadInstances = async () => {
     try {
-      localStorage.setItem('ollama-instances', JSON.stringify(newInstances));
+      setLoading(true);
+      
+      // First try to migrate from localStorage if needed
+      const migrationResult = await credentialsService.migrateOllamaFromLocalStorage();
+      if (migrationResult.migrated) {
+        showToast(`Migrated ${migrationResult.instanceCount} Ollama instances to database`, 'success');
+      }
+      
+      // Load instances from database
+      const databaseInstances = await credentialsService.getOllamaInstances();
+      setInstances(databaseInstances);
+      onConfigChange(databaseInstances);
+    } catch (error) {
+      console.error('Failed to load Ollama instances from database:', error);
+      showToast('Failed to load Ollama configuration from database', 'error');
+      
+      // Fallback to localStorage
+      try {
+        const saved = localStorage.getItem('ollama-instances');
+        if (saved) {
+          const localInstances = JSON.parse(saved);
+          setInstances(localInstances);
+          onConfigChange(localInstances);
+          showToast('Loaded Ollama configuration from local backup', 'warning');
+        }
+      } catch (localError) {
+        console.error('Failed to load from localStorage as fallback:', localError);
+      }
+    } finally {
+      setLoading(false);
+    }
+  };
+
+  // Save instances to database
+  const saveInstances = async (newInstances: OllamaInstance[]) => {
+    try {
+      setLoading(true);
+      await credentialsService.setOllamaInstances(newInstances);
       setInstances(newInstances);
+      onConfigChange(newInstances);
+      
+      // Also backup to localStorage for fallback
+      try {
+        localStorage.setItem('ollama-instances', JSON.stringify(newInstances));
+      } catch (localError) {
+        console.warn('Failed to backup to localStorage:', localError);
+      }
     } catch (error) {
-      console.error('Failed to save Ollama instances to localStorage:', error);
-      showToast('Failed to save Ollama configuration', 'error');
+      console.error('Failed to save Ollama instances to database:', error);
+      showToast('Failed to save Ollama configuration to database', 'error');
+    } finally {
+      setLoading(false);
     }
   };
 
@@ -154,7 +166,7 @@ const OllamaConfigurationPanel: React.FC<OllamaConfigurationPanelProps> = ({
   };
 
   // Add new instance
-  const handleAddInstance = () => {
+  const handleAddInstance = async () => {
     if (!newInstanceUrl.trim() || !newInstanceName.trim()) {
       showToast('Please provide both URL and name for the new instance', 'error');
       return;
@@ -187,16 +199,28 @@ const OllamaConfigurationPanel: React.FC<OllamaConfigurationPanelProps> = ({
       loadBalancingWeight: 100
     };
 
-    saveInstances([...instances, newInstance]);
-    setNewInstanceUrl('');
-    setNewInstanceName('');
-    setShowAddInstance(false);
-    
-    showToast(`Added new Ollama instance: ${newInstance.name}`, 'success');
+    try {
+      setLoading(true);
+      await credentialsService.addOllamaInstance(newInstance);
+      
+      // Reload instances from database to get updated list
+      await loadInstances();
+      
+      setNewInstanceUrl('');
+      setNewInstanceName('');
+      setShowAddInstance(false);
+      
+      showToast(`Added new Ollama instance: ${newInstance.name}`, 'success');
+    } catch (error) {
+      console.error('Failed to add Ollama instance:', error);
+      showToast(`Failed to add Ollama instance: ${error instanceof Error ? error.message : 'Unknown error'}`, 'error');
+    } finally {
+      setLoading(false);
+    }
   };
 
   // Remove instance
-  const handleRemoveInstance = (instanceId: string) => {
+  const handleRemoveInstance = async (instanceId: string) => {
     const instance = instances.find(inst => inst.id === instanceId);
     if (!instance) return;
 
@@ -206,53 +230,78 @@ const OllamaConfigurationPanel: React.FC<OllamaConfigurationPanelProps> = ({
       return;
     }
 
-    const filtered = instances.filter(inst => inst.id !== instanceId);
-    
-    // If we're removing the primary instance, make the first remaining one primary
-    if (instance.isPrimary && filtered.length > 0) {
-      filtered[0] = { ...filtered[0], isPrimary: true };
+    try {
+      setLoading(true);
+      await credentialsService.removeOllamaInstance(instanceId);
+      
+      // Reload instances from database to get updated list
+      await loadInstances();
+      
+      showToast(`Removed Ollama instance: ${instance.name}`, 'success');
+    } catch (error) {
+      console.error('Failed to remove Ollama instance:', error);
+      showToast(`Failed to remove Ollama instance: ${error instanceof Error ? error.message : 'Unknown error'}`, 'error');
+    } finally {
+      setLoading(false);
     }
-    
-    saveInstances(filtered);
-
-    showToast(`Removed Ollama instance: ${instance.name}`, 'success');
   };
 
   // Update instance URL
-  const handleUpdateInstanceUrl = (instanceId: string, newUrl: string) => {
-    const updatedInstances = instances.map(inst =>
-      inst.id === instanceId 
-        ? { ...inst, baseUrl: newUrl, isHealthy: undefined, lastHealthCheck: undefined }
-        : inst
-    );
-    saveInstances(updatedInstances);
+  const handleUpdateInstanceUrl = async (instanceId: string, newUrl: string) => {
+    try {
+      await credentialsService.updateOllamaInstance(instanceId, { 
+        baseUrl: newUrl, 
+        isHealthy: undefined, 
+        lastHealthCheck: undefined 
+      });
+      await loadInstances(); // Reload to get updated data
+    } catch (error) {
+      console.error('Failed to update Ollama instance URL:', error);
+      showToast('Failed to update instance URL', 'error');
+    }
   };
 
   // Toggle instance enabled state
-  const handleToggleInstance = (instanceId: string) => {
-    const updatedInstances = instances.map(inst =>
-      inst.id === instanceId 
-        ? { ...inst, isEnabled: !inst.isEnabled }
-        : inst
-    );
-    saveInstances(updatedInstances);
+  const handleToggleInstance = async (instanceId: string) => {
+    const instance = instances.find(inst => inst.id === instanceId);
+    if (!instance) return;
+
+    try {
+      await credentialsService.updateOllamaInstance(instanceId, { 
+        isEnabled: !instance.isEnabled 
+      });
+      await loadInstances(); // Reload to get updated data
+    } catch (error) {
+      console.error('Failed to toggle Ollama instance:', error);
+      showToast('Failed to toggle instance state', 'error');
+    }
   };
 
   // Set instance as primary
-  const handleSetPrimary = (instanceId: string) => {
-    const updatedInstances = instances.map(inst => ({
-      ...inst,
-      isPrimary: inst.id === instanceId
-    }));
-    saveInstances(updatedInstances);
+  const handleSetPrimary = async (instanceId: string) => {
+    try {
+      // Update all instances - only the specified one should be primary
+      await saveInstances(instances.map(inst => ({
+        ...inst,
+        isPrimary: inst.id === instanceId
+      })));
+    } catch (error) {
+      console.error('Failed to set primary Ollama instance:', error);
+      showToast('Failed to set primary instance', 'error');
+    }
   };
 
+  // Load instances from database on mount
+  useEffect(() => {
+    loadInstances();
+  }, []); // Empty dependency array - load only on mount
+
   // Notify parent of configuration changes
   useEffect(() => {
     onConfigChange(instances);
   }, [instances, onConfigChange]);
 
-  // Auto-test primary instance on mount
+  // Auto-test primary instance when component becomes visible
   useEffect(() => {
     if (isVisible && instances.length > 0) {
       const primaryInstance = instances.find(inst => inst.isPrimary);
@@ -260,7 +309,7 @@ const OllamaConfigurationPanel: React.FC<OllamaConfigurationPanelProps> = ({
         handleTestConnection(primaryInstance.id);
       }
     }
-  }, [isVisible]);
+  }, [isVisible, instances.length]);
 
   if (!isVisible) return null;
 
diff --git a/archon-ui-main/src/services/credentialsService.ts b/archon-ui-main/src/services/credentialsService.ts
index d3e1096..9945a68 100644
--- a/archon-ui-main/src/services/credentialsService.ts
+++ b/archon-ui-main/src/services/credentialsService.ts
@@ -53,6 +53,19 @@ export interface CodeExtractionSettings {
   ENABLE_CODE_SUMMARIES: boolean;
 }
 
+export interface OllamaInstance {
+  id: string;
+  name: string;
+  baseUrl: string;
+  isEnabled: boolean;
+  isPrimary: boolean;
+  loadBalancingWeight: number;
+  isHealthy?: boolean;
+  responseTimeMs?: number;
+  modelsAvailable?: number;
+  lastHealthCheck?: string;
+}
+
 import { getApiUrl } from '../config/api';
 
 class CredentialsService {
@@ -291,6 +304,191 @@ class CredentialsService {
     
     await Promise.all(promises);
   }
+
+  // Ollama Instance Management Methods
+  async getOllamaInstances(): Promise<OllamaInstance[]> {
+    try {
+      const response = await fetch(`${this.baseUrl}/api/provider-config/current`);
+      if (!response.ok) {
+        throw new Error('Failed to fetch Ollama instances from database');
+      }
+      
+      const data = await response.json();
+      
+      // Convert API format to frontend format
+      const instances: OllamaInstance[] = data.ollama_instances?.map((inst: any) => ({
+        id: inst.id,
+        name: inst.name,
+        baseUrl: inst.base_url,
+        isEnabled: inst.is_enabled,
+        isPrimary: inst.is_primary,
+        loadBalancingWeight: inst.load_balancing_weight,
+        isHealthy: inst.is_healthy,
+        responseTimeMs: inst.response_time_ms,
+        modelsAvailable: inst.models_available,
+        lastHealthCheck: inst.last_health_check
+      })) || [];
+      
+      return instances;
+    } catch (error) {
+      console.error('Error fetching Ollama instances from database:', error);
+      throw error;
+    }
+  }
+
+  async setOllamaInstances(instances: OllamaInstance[]): Promise<void> {
+    try {
+      // Convert frontend format to API format
+      const apiInstances = instances.map(inst => ({
+        id: inst.id,
+        name: inst.name,
+        base_url: inst.baseUrl,
+        is_enabled: inst.isEnabled,
+        is_primary: inst.isPrimary,
+        load_balancing_weight: inst.loadBalancingWeight,
+        health_check_enabled: true
+      }));
+
+      const response = await fetch(`${this.baseUrl}/api/provider-config/update`, {
+        method: 'PUT',
+        headers: {
+          'Content-Type': 'application/json',
+        },
+        body: JSON.stringify({
+          llm_provider: 'ollama', // Assuming ollama provider
+          embedding_provider: 'ollama',
+          ollama_instances: apiInstances,
+          provider_preferences: {}
+        }),
+      });
+
+      if (!response.ok) {
+        const errorData = await response.text();
+        throw new Error(`Failed to save Ollama instances to database: ${errorData}`);
+      }
+    } catch (error) {
+      console.error('Error saving Ollama instances to database:', error);
+      throw error;
+    }
+  }
+
+  async addOllamaInstance(instance: OllamaInstance): Promise<void> {
+    try {
+      // Convert frontend format to API format
+      const apiInstance = {
+        id: instance.id,
+        name: instance.name,
+        base_url: instance.baseUrl,
+        is_enabled: instance.isEnabled,
+        is_primary: instance.isPrimary,
+        load_balancing_weight: instance.loadBalancingWeight,
+        health_check_enabled: true
+      };
+
+      const response = await fetch(`${this.baseUrl}/api/provider-config/ollama/add-instance`, {
+        method: 'POST',
+        headers: {
+          'Content-Type': 'application/json',
+        },
+        body: JSON.stringify(apiInstance),
+      });
+
+      if (!response.ok) {
+        const errorData = await response.text();
+        throw new Error(`Failed to add Ollama instance to database: ${errorData}`);
+      }
+    } catch (error) {
+      console.error('Error adding Ollama instance to database:', error);
+      throw error;
+    }
+  }
+
+  async removeOllamaInstance(instanceId: string): Promise<void> {
+    try {
+      const response = await fetch(`${this.baseUrl}/api/provider-config/ollama/remove-instance/${instanceId}`, {
+        method: 'DELETE',
+      });
+
+      if (!response.ok) {
+        const errorData = await response.text();
+        throw new Error(`Failed to remove Ollama instance from database: ${errorData}`);
+      }
+    } catch (error) {
+      console.error('Error removing Ollama instance from database:', error);
+      throw error;
+    }
+  }
+
+  async updateOllamaInstance(instanceId: string, updates: Partial<OllamaInstance>): Promise<void> {
+    try {
+      // Get current instances, update the specific one, then save all
+      const instances = await this.getOllamaInstances();
+      const instanceIndex = instances.findIndex(inst => inst.id === instanceId);
+      
+      if (instanceIndex === -1) {
+        throw new Error(`Ollama instance with ID ${instanceId} not found`);
+      }
+
+      // Apply updates
+      instances[instanceIndex] = { ...instances[instanceIndex], ...updates };
+
+      // Save updated instances
+      await this.setOllamaInstances(instances);
+    } catch (error) {
+      console.error('Error updating Ollama instance in database:', error);
+      throw error;
+    }
+  }
+
+  async migrateOllamaFromLocalStorage(): Promise<{ migrated: boolean; instanceCount: number }> {
+    try {
+      // Check if localStorage has Ollama instances
+      const localStorageData = localStorage.getItem('ollama-instances');
+      if (!localStorageData) {
+        return { migrated: false, instanceCount: 0 };
+      }
+
+      const localInstances = JSON.parse(localStorageData);
+      if (!Array.isArray(localInstances) || localInstances.length === 0) {
+        return { migrated: false, instanceCount: 0 };
+      }
+
+      // Check if database already has instances
+      const existingInstances = await this.getOllamaInstances();
+      if (existingInstances.length > 0) {
+        // Database already has instances, don't migrate
+        return { migrated: false, instanceCount: existingInstances.length };
+      }
+
+      // Migrate localStorage instances to database
+      const instancesToMigrate: OllamaInstance[] = localInstances.map((inst: any) => ({
+        id: inst.id || `migrated-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
+        name: inst.name || 'Migrated Instance',
+        baseUrl: inst.baseUrl || inst.url || 'http://localhost:11434',
+        isEnabled: inst.isEnabled !== false, // Default to true
+        isPrimary: inst.isPrimary || false,
+        loadBalancingWeight: inst.loadBalancingWeight || 100,
+        isHealthy: inst.isHealthy,
+        responseTimeMs: inst.responseTimeMs,
+        modelsAvailable: inst.modelsAvailable,
+        lastHealthCheck: inst.lastHealthCheck
+      }));
+
+      // Ensure at least one instance is marked as primary
+      if (!instancesToMigrate.some(inst => inst.isPrimary)) {
+        instancesToMigrate[0].isPrimary = true;
+      }
+
+      await this.setOllamaInstances(instancesToMigrate);
+
+      console.log(`Successfully migrated ${instancesToMigrate.length} Ollama instances from localStorage to database`);
+      
+      return { migrated: true, instanceCount: instancesToMigrate.length };
+    } catch (error) {
+      console.error('Error migrating Ollama instances from localStorage:', error);
+      throw error;
+    }
+  }
 }
 
 export const credentialsService = new CredentialsService(); 
\ No newline at end of file
diff --git a/python/src/server/api_routes/provider_config_api.py b/python/src/server/api_routes/provider_config_api.py
index 3743eb4..dfd18d5 100644
--- a/python/src/server/api_routes/provider_config_api.py
+++ b/python/src/server/api_routes/provider_config_api.py
@@ -78,18 +78,22 @@ async def get_current_provider_config() -> MultiProviderConfig:
         llm_provider = rag_settings.get("LLM_PROVIDER", "openai")
         embedding_provider = rag_settings.get("LLM_PROVIDER", "openai")  # For now, use same provider
         
-        # Get Ollama instances - for now, create from single URL
-        ollama_base_url = rag_settings.get("LLM_BASE_URL", "http://localhost:11434")
-        ollama_instances = [
-            OllamaInstanceConfig(
-                id="default",
-                name="Default Ollama",
-                base_url=ollama_base_url,
-                is_primary=True,
-                is_enabled=True,
-                load_balancing_weight=1
+        # Get Ollama instances from database
+        ollama_instances_data = await credential_service.get_ollama_instances()
+        
+        # Convert database format to API format
+        ollama_instances = []
+        for instance_data in ollama_instances_data:
+            ollama_instance = OllamaInstanceConfig(
+                id=instance_data.get("id"),
+                name=instance_data.get("name"),
+                base_url=instance_data.get("baseUrl"),
+                is_primary=instance_data.get("isPrimary", False),
+                is_enabled=instance_data.get("isEnabled", True),
+                load_balancing_weight=instance_data.get("loadBalancingWeight", 1),
+                health_check_enabled=True
             )
-        ]
+            ollama_instances.append(ollama_instance)
         
         config = MultiProviderConfig(
             llm_provider=llm_provider,
@@ -98,7 +102,7 @@ async def get_current_provider_config() -> MultiProviderConfig:
             provider_preferences=rag_settings
         )
         
-        logger.info(f"Retrieved multi-provider config with {len(ollama_instances)} Ollama instances")
+        logger.info(f"Retrieved multi-provider config with {len(ollama_instances)} Ollama instances from database")
         return config
         
     except Exception as e:
@@ -124,28 +128,23 @@ async def update_provider_config(
         
         # Update Ollama instances configuration
         if request.ollama_instances:
-            primary_instance = next(
-                (inst for inst in request.ollama_instances if inst.is_primary), 
-                request.ollama_instances[0]
-            )
-            
-            await credential_service.set_credential(
-                "LLM_BASE_URL",
-                primary_instance.base_url,
-                category="rag_strategy",
-                description="Primary Ollama base URL"
-            )
+            # Convert API format to database format
+            ollama_instances_data = []
+            for inst in request.ollama_instances:
+                instance_data = {
+                    "id": inst.id,
+                    "name": inst.name,
+                    "baseUrl": inst.base_url,
+                    "isEnabled": inst.is_enabled,
+                    "isPrimary": inst.is_primary,
+                    "loadBalancingWeight": inst.load_balancing_weight
+                }
+                ollama_instances_data.append(instance_data)
             
-            # Store multi-instance config for future use
-            # For now, we'll store this as a JSON string in credentials
-            import json
-            ollama_config = [inst.dict() for inst in request.ollama_instances]
-            await credential_service.set_credential(
-                "OLLAMA_INSTANCES",
-                json.dumps(ollama_config),
-                category="rag_strategy",
-                description="Multi-instance Ollama configuration"
-            )
+            # Use the new database persistence method with validation
+            success = await credential_service.set_ollama_instances(ollama_instances_data)
+            if not success:
+                raise HTTPException(status_code=500, detail="Failed to store Ollama instances configuration")
         
         # Update provider preferences
         for key, value in request.provider_preferences.items():
@@ -352,23 +351,20 @@ async def add_ollama_instance(
     try:
         logger.info(f"Adding Ollama instance: {instance.name} at {instance.base_url}")
         
-        # Get current configuration
-        current_config = await get_current_provider_config()
-        
-        # Check if instance already exists
-        existing_ids = [inst.id for inst in current_config.ollama_instances]
-        if instance.id in existing_ids:
-            raise HTTPException(status_code=400, detail=f"Instance with ID {instance.id} already exists")
-        
-        existing_urls = [inst.base_url for inst in current_config.ollama_instances]
-        if instance.base_url in existing_urls:
-            raise HTTPException(status_code=400, detail=f"Instance with URL {instance.base_url} already exists")
-        
-        # Add the new instance
-        current_config.ollama_instances.append(instance)
+        # Convert API format to database format
+        instance_data = {
+            "id": instance.id,
+            "name": instance.name,
+            "baseUrl": instance.base_url,
+            "isEnabled": instance.is_enabled,
+            "isPrimary": instance.is_primary,
+            "loadBalancingWeight": instance.load_balancing_weight
+        }
         
-        # Update configuration
-        await update_provider_config(current_config, background_tasks)
+        # Use the new database method with built-in validation
+        success = await credential_service.add_ollama_instance(instance_data)
+        if not success:
+            raise HTTPException(status_code=500, detail="Failed to add Ollama instance to database")
         
         # Test connectivity to new instance
         health_status = await provider_discovery_service.check_provider_health(
@@ -397,37 +393,14 @@ async def remove_ollama_instance(
     try:
         logger.info(f"Removing Ollama instance: {instance_id}")
         
-        # Get current configuration
-        current_config = await get_current_provider_config()
-        
-        # Find and remove the instance
-        instance_to_remove = None
-        for i, inst in enumerate(current_config.ollama_instances):
-            if inst.id == instance_id:
-                instance_to_remove = current_config.ollama_instances.pop(i)
-                break
-        
-        if not instance_to_remove:
-            raise HTTPException(status_code=404, detail=f"Instance with ID {instance_id} not found")
-        
-        # Ensure at least one instance remains if Ollama is the active provider
-        if (current_config.llm_provider == "ollama" or current_config.embedding_provider == "ollama"):
-            if not current_config.ollama_instances:
-                raise HTTPException(
-                    status_code=400, 
-                    detail="Cannot remove the last Ollama instance while Ollama provider is active"
-                )
-        
-        # If removing primary instance, promote another
-        if instance_to_remove.is_primary and current_config.ollama_instances:
-            current_config.ollama_instances[0].is_primary = True
-        
-        # Update configuration
-        await update_provider_config(current_config, background_tasks)
+        # Use the new database method with built-in validation
+        success = await credential_service.remove_ollama_instance(instance_id)
+        if not success:
+            raise HTTPException(status_code=500, detail="Failed to remove Ollama instance from database")
         
         return {
             "success": True,
-            "message": f"Ollama instance {instance_to_remove.name} removed successfully",
+            "message": f"Ollama instance with ID {instance_id} removed successfully",
             "removed_instance_id": instance_id
         }
         
diff --git a/python/src/server/services/credential_service.py b/python/src/server/services/credential_service.py
index e8f3ad6..ab8f45a 100644
--- a/python/src/server/services/credential_service.py
+++ b/python/src/server/services/credential_service.py
@@ -476,6 +476,412 @@ class CredentialService:
             logger.error(f"Error setting active provider {provider} for {service_type}: {e}")
             return False
 
+    # Ollama Instance Management Methods
+    async def get_ollama_instances(self) -> list[dict]:
+        """
+        Get all Ollama instances from database.
+        
+        Returns:
+            List of OllamaInstance dictionaries with structure:
+            {
+                "id": str,
+                "name": str,
+                "baseUrl": str,
+                "isEnabled": bool,
+                "isPrimary": bool,
+                "loadBalancingWeight": int,
+                "isHealthy": bool (optional),
+                "responseTimeMs": int (optional),
+                "modelsAvailable": int (optional),
+                "lastHealthCheck": str (optional)
+            }
+        """
+        try:
+            import json
+            
+            # Get OLLAMA_INSTANCES from rag_strategy category
+            instances_raw = await self.get_credential("OLLAMA_INSTANCES", default=None)
+            
+            if instances_raw:
+                # Parse JSON string to list of instances
+                if isinstance(instances_raw, str):
+                    instances = json.loads(instances_raw)
+                else:
+                    instances = instances_raw
+                    
+                # Validate structure
+                if not isinstance(instances, list):
+                    logger.warning("OLLAMA_INSTANCES is not a list, creating default instance")
+                    return await self._create_default_ollama_instances()
+                    
+                # Validate each instance has required fields
+                validated_instances = []
+                for instance in instances:
+                    if not isinstance(instance, dict):
+                        continue
+                        
+                    # Ensure required fields exist
+                    required_fields = ["id", "name", "baseUrl", "isEnabled", "isPrimary", "loadBalancingWeight"]
+                    if all(field in instance for field in required_fields):
+                        validated_instances.append(instance)
+                    else:
+                        logger.warning(f"Ollama instance missing required fields: {instance}")
+                
+                if validated_instances:
+                    logger.debug(f"Retrieved {len(validated_instances)} Ollama instances from database")
+                    return validated_instances
+                else:
+                    logger.info("No valid Ollama instances found, creating default")
+                    return await self._create_default_ollama_instances()
+            else:
+                # No instances stored yet, create default based on LLM_BASE_URL
+                logger.info("No OLLAMA_INSTANCES found, creating default from LLM_BASE_URL")
+                return await self._create_default_ollama_instances()
+                
+        except json.JSONDecodeError as e:
+            logger.error(f"Error parsing OLLAMA_INSTANCES JSON: {e}")
+            return await self._create_default_ollama_instances()
+        except Exception as e:
+            logger.error(f"Error getting Ollama instances: {e}")
+            return await self._create_default_ollama_instances()
+
+    async def _create_default_ollama_instances(self) -> list[dict]:
+        """Create default Ollama instance based on existing LLM_BASE_URL."""
+        import uuid
+        
+        # Get existing LLM_BASE_URL or use default
+        base_url = await self.get_credential("LLM_BASE_URL", default="http://localhost:11434")
+        
+        # Clean up base URL (remove /v1 suffix if present)
+        if base_url.endswith("/v1"):
+            base_url = base_url[:-3]
+            
+        default_instance = {
+            "id": str(uuid.uuid4()),
+            "name": "Primary Ollama Instance",
+            "baseUrl": base_url,
+            "isEnabled": True,
+            "isPrimary": True,
+            "loadBalancingWeight": 100
+        }
+        
+        # Save default instance to database
+        await self.set_ollama_instances([default_instance])
+        
+        logger.info(f"Created default Ollama instance: {base_url}")
+        return [default_instance]
+
+    async def set_ollama_instances(self, instances: list[dict]) -> bool:
+        """
+        Store Ollama instances to database.
+        
+        Args:
+            instances: List of OllamaInstance dictionaries
+            
+        Returns:
+            bool: Success status
+        """
+        try:
+            import json
+            
+            # Validate instances structure
+            if not isinstance(instances, list):
+                raise ValueError("Instances must be a list")
+                
+            # Validate each instance
+            validated_instances = []
+            primary_count = 0
+            
+            for instance in instances:
+                if not isinstance(instance, dict):
+                    raise ValueError(f"Instance must be a dict: {instance}")
+                    
+                # Check required fields
+                required_fields = ["id", "name", "baseUrl", "isEnabled", "isPrimary", "loadBalancingWeight"]
+                missing_fields = [field for field in required_fields if field not in instance]
+                if missing_fields:
+                    raise ValueError(f"Instance missing required fields {missing_fields}: {instance}")
+                
+                # Validate field types
+                if not isinstance(instance["id"], str) or not instance["id"]:
+                    raise ValueError(f"Instance id must be non-empty string: {instance['id']}")
+                    
+                if not isinstance(instance["name"], str) or not instance["name"]:
+                    raise ValueError(f"Instance name must be non-empty string: {instance['name']}")
+                    
+                if not isinstance(instance["baseUrl"], str) or not instance["baseUrl"]:
+                    raise ValueError(f"Instance baseUrl must be non-empty string: {instance['baseUrl']}")
+                    
+                if not isinstance(instance["isEnabled"], bool):
+                    raise ValueError(f"Instance isEnabled must be boolean: {instance['isEnabled']}")
+                    
+                if not isinstance(instance["isPrimary"], bool):
+                    raise ValueError(f"Instance isPrimary must be boolean: {instance['isPrimary']}")
+                    
+                if not isinstance(instance["loadBalancingWeight"], int) or instance["loadBalancingWeight"] < 1 or instance["loadBalancingWeight"] > 100:
+                    raise ValueError(f"Instance loadBalancingWeight must be int 1-100: {instance['loadBalancingWeight']}")
+                
+                # Count primary instances
+                if instance["isPrimary"]:
+                    primary_count += 1
+                    
+                validated_instances.append(instance)
+            
+            # Ensure exactly one primary instance
+            if primary_count == 0 and validated_instances:
+                # Make first instance primary if none specified
+                validated_instances[0]["isPrimary"] = True
+                primary_count = 1
+                logger.info("No primary instance specified, made first instance primary")
+            elif primary_count > 1:
+                # Make only the first primary instance primary
+                primary_found = False
+                for instance in validated_instances:
+                    if instance["isPrimary"] and not primary_found:
+                        primary_found = True
+                    elif instance["isPrimary"]:
+                        instance["isPrimary"] = False
+                logger.warning(f"Multiple primary instances found, kept only the first")
+            
+            # Serialize to JSON
+            instances_json = json.dumps(validated_instances, separators=(',', ':'))
+            
+            # Store in database
+            success = await self.set_credential(
+                "OLLAMA_INSTANCES",
+                instances_json,
+                is_encrypted=False,
+                category="rag_strategy",
+                description="Ollama instances configuration for load balancing"
+            )
+            
+            if success:
+                # Update LLM_BASE_URL to primary instance for backward compatibility
+                primary_instance = next((inst for inst in validated_instances if inst["isPrimary"]), None)
+                if primary_instance:
+                    primary_url = primary_instance["baseUrl"]
+                    if not primary_url.endswith("/v1"):
+                        primary_url += "/v1"
+                    await self.set_credential(
+                        "LLM_BASE_URL",
+                        primary_url,
+                        is_encrypted=False,
+                        category="rag_strategy",
+                        description="Primary Ollama base URL (auto-updated from instances)"
+                    )
+                
+                logger.info(f"Successfully stored {len(validated_instances)} Ollama instances")
+                return True
+            else:
+                logger.error("Failed to store Ollama instances to database")
+                return False
+                
+        except Exception as e:
+            logger.error(f"Error setting Ollama instances: {e}")
+            return False
+
+    async def add_ollama_instance(self, instance: dict) -> bool:
+        """
+        Add a new Ollama instance.
+        
+        Args:
+            instance: OllamaInstance dictionary
+            
+        Returns:
+            bool: Success status
+        """
+        try:
+            # Get existing instances
+            existing_instances = await self.get_ollama_instances()
+            
+            # Check for duplicate ID or URL
+            instance_id = instance.get("id")
+            instance_url = instance.get("baseUrl")
+            
+            for existing in existing_instances:
+                if existing.get("id") == instance_id:
+                    raise ValueError(f"Instance with ID {instance_id} already exists")
+                if existing.get("baseUrl") == instance_url:
+                    raise ValueError(f"Instance with URL {instance_url} already exists")
+            
+            # If this is marked as primary, unmark existing primary
+            if instance.get("isPrimary", False):
+                for existing in existing_instances:
+                    existing["isPrimary"] = False
+            
+            # Add new instance
+            existing_instances.append(instance)
+            
+            # Save updated list
+            return await self.set_ollama_instances(existing_instances)
+            
+        except Exception as e:
+            logger.error(f"Error adding Ollama instance: {e}")
+            return False
+
+    async def remove_ollama_instance(self, instance_id: str) -> bool:
+        """
+        Remove an Ollama instance by ID.
+        
+        Args:
+            instance_id: ID of instance to remove
+            
+        Returns:
+            bool: Success status
+        """
+        try:
+            # Get existing instances
+            existing_instances = await self.get_ollama_instances()
+            
+            # Find instance to remove
+            instance_to_remove = None
+            remaining_instances = []
+            
+            for instance in existing_instances:
+                if instance.get("id") == instance_id:
+                    instance_to_remove = instance
+                else:
+                    remaining_instances.append(instance)
+            
+            if not instance_to_remove:
+                raise ValueError(f"Instance with ID {instance_id} not found")
+            
+            # Don't allow removing the last instance
+            if len(remaining_instances) == 0:
+                raise ValueError("Cannot remove the last Ollama instance")
+            
+            # If removing primary instance, make first remaining instance primary
+            if instance_to_remove.get("isPrimary", False) and remaining_instances:
+                remaining_instances[0]["isPrimary"] = True
+                logger.info(f"Made instance {remaining_instances[0]['id']} primary after removing primary instance")
+            
+            # Save updated list
+            success = await self.set_ollama_instances(remaining_instances)
+            
+            if success:
+                logger.info(f"Successfully removed Ollama instance: {instance_id}")
+            
+            return success
+            
+        except Exception as e:
+            logger.error(f"Error removing Ollama instance {instance_id}: {e}")
+            return False
+
+    async def update_ollama_instance(self, instance_id: str, updates: dict) -> bool:
+        """
+        Update an Ollama instance with new data.
+        
+        Args:
+            instance_id: ID of instance to update
+            updates: Dictionary of fields to update
+            
+        Returns:
+            bool: Success status
+        """
+        try:
+            # Get existing instances
+            existing_instances = await self.get_ollama_instances()
+            
+            # Find instance to update
+            instance_found = False
+            
+            for i, instance in enumerate(existing_instances):
+                if instance.get("id") == instance_id:
+                    # Apply updates
+                    for key, value in updates.items():
+                        if key in ["id", "name", "baseUrl", "isEnabled", "isPrimary", "loadBalancingWeight", 
+                                 "isHealthy", "responseTimeMs", "modelsAvailable", "lastHealthCheck"]:
+                            instance[key] = value
+                    
+                    # If this instance is being set as primary, unmark others
+                    if updates.get("isPrimary", False):
+                        for j, other_instance in enumerate(existing_instances):
+                            if j != i:
+                                other_instance["isPrimary"] = False
+                    
+                    instance_found = True
+                    break
+            
+            if not instance_found:
+                raise ValueError(f"Instance with ID {instance_id} not found")
+            
+            # Save updated list
+            success = await self.set_ollama_instances(existing_instances)
+            
+            if success:
+                logger.debug(f"Successfully updated Ollama instance {instance_id} with {updates}")
+            
+            return success
+            
+        except Exception as e:
+            logger.error(f"Error updating Ollama instance {instance_id}: {e}")
+            return False
+
+    async def get_primary_ollama_instance(self) -> dict | None:
+        """
+        Get the primary Ollama instance.
+        
+        Returns:
+            Primary instance dict or None if not found
+        """
+        try:
+            instances = await self.get_ollama_instances()
+            
+            for instance in instances:
+                if instance.get("isPrimary", False) and instance.get("isEnabled", True):
+                    return instance
+            
+            # Fallback to first enabled instance
+            for instance in instances:
+                if instance.get("isEnabled", True):
+                    return instance
+            
+            # Fallback to first instance regardless of enabled status
+            if instances:
+                return instances[0]
+                
+            return None
+            
+        except Exception as e:
+            logger.error(f"Error getting primary Ollama instance: {e}")
+            return None
+
+    async def get_healthy_ollama_instances(self) -> list[dict]:
+        """
+        Get all healthy and enabled Ollama instances for load balancing.
+        
+        Returns:
+            List of healthy instance dicts
+        """
+        try:
+            instances = await self.get_ollama_instances()
+            
+            healthy_instances = []
+            for instance in instances:
+                if (instance.get("isEnabled", True) and 
+                    instance.get("isHealthy", True)):  # Default to healthy if not specified
+                    healthy_instances.append(instance)
+            
+            # If no healthy instances, return enabled instances
+            if not healthy_instances:
+                enabled_instances = [inst for inst in instances if inst.get("isEnabled", True)]
+                if enabled_instances:
+                    logger.warning("No healthy Ollama instances found, returning enabled instances")
+                    return enabled_instances
+            
+            # If no enabled instances, return primary instance as fallback
+            if not healthy_instances:
+                primary = await self.get_primary_ollama_instance()
+                if primary:
+                    logger.warning("No enabled Ollama instances found, returning primary as fallback")
+                    return [primary]
+            
+            return healthy_instances
+            
+        except Exception as e:
+            logger.error(f"Error getting healthy Ollama instances: {e}")
+            return []
+
 
 # Global instance
 credential_service = CredentialService()
diff --git a/python/src/server/services/llm_provider_service.py b/python/src/server/services/llm_provider_service.py
index 3a6f424..700bbbf 100644
--- a/python/src/server/services/llm_provider_service.py
+++ b/python/src/server/services/llm_provider_service.py
@@ -21,6 +21,81 @@ _settings_cache: dict[str, tuple[Any, float]] = {}
 _CACHE_TTL_SECONDS = 300  # 5 minutes
 
 
+async def get_best_ollama_instance(model_name: str = None) -> dict | None:
+    """
+    Select the best Ollama instance for load balancing.
+    
+    Args:
+        model_name: Optional model name for model-specific routing
+        
+    Returns:
+        Best instance dict or None if no healthy instances available
+    """
+    try:
+        # Get healthy instances from database
+        healthy_instances = await credential_service.get_healthy_ollama_instances()
+        
+        if not healthy_instances:
+            logger.warning("No healthy Ollama instances available, falling back to primary")
+            primary_instance = await credential_service.get_primary_ollama_instance()
+            return primary_instance
+        
+        if len(healthy_instances) == 1:
+            # Only one healthy instance, use it
+            return healthy_instances[0]
+        
+        # Load balancing logic: weighted random selection
+        import random
+        
+        total_weight = 0
+        weighted_instances = []
+        
+        for instance in healthy_instances:
+            # Base weight from configuration
+            base_weight = instance.get("loadBalancingWeight", 100)
+            
+            # Health factor (prefer faster instances)
+            response_time = instance.get("responseTimeMs", 1000)
+            health_factor = 1.0 if response_time < 1000 else 0.5
+            
+            # Model availability factor (prefer instances with the required model)
+            model_factor = 1.0
+            if model_name:
+                available_models = instance.get("modelsAvailable", 0)
+                # Simple heuristic: prefer instances with more models
+                model_factor = 1.2 if available_models > 5 else 1.0
+            
+            # Calculate final weight
+            final_weight = base_weight * health_factor * model_factor
+            total_weight += final_weight
+            weighted_instances.append((instance, final_weight))
+        
+        # Weighted random selection
+        if total_weight > 0:
+            random_value = random.uniform(0, total_weight)
+            cumulative_weight = 0
+            
+            for instance, weight in weighted_instances:
+                cumulative_weight += weight
+                if random_value <= cumulative_weight:
+                    logger.debug(f"Selected Ollama instance {instance['id']} ({instance['name']}) with weight {weight:.2f}")
+                    return instance
+        
+        # Fallback: return first healthy instance
+        logger.debug("Weighted selection failed, using first healthy instance")
+        return healthy_instances[0]
+        
+    except Exception as e:
+        logger.error(f"Error selecting best Ollama instance: {e}")
+        # Fallback to primary instance
+        try:
+            primary_instance = await credential_service.get_primary_ollama_instance()
+            return primary_instance
+        except Exception as fallback_error:
+            logger.error(f"Error getting primary Ollama instance: {fallback_error}")
+            return None
+
+
 def _get_cached_settings(key: str) -> Any | None:
     """Get cached settings if not expired."""
     if key in _settings_cache:
@@ -101,9 +176,20 @@ async def get_llm_client(provider: str | None = None, use_embedding_provider: bo
             logger.info("OpenAI client created successfully")
 
         elif provider_name == "ollama":
-            # Ensure base_url doesn't have double /v1 paths
-            # Database stores http://localhost:11434/v1, OpenAI client will add /chat/completions
-            clean_base_url = base_url or "http://localhost:11434/v1"
+            # Use load balancing to select the best Ollama instance
+            best_instance = await get_best_ollama_instance()
+            
+            if not best_instance:
+                raise ValueError("No Ollama instances available")
+            
+            # Get the base URL from the selected instance
+            instance_base_url = best_instance.get("baseUrl", "http://localhost:11434")
+            
+            # Ensure base_url has /v1 suffix for OpenAI client compatibility
+            if not instance_base_url.endswith("/v1"):
+                clean_base_url = f"{instance_base_url}/v1"
+            else:
+                clean_base_url = instance_base_url
             
             # Ollama requires an API key in the client but doesn't actually use it
             # Add timeout and disable retries for fast failure detection
@@ -113,7 +199,7 @@ async def get_llm_client(provider: str | None = None, use_embedding_provider: bo
                 timeout=60.0,  # 1-minute timeout to fail fast on overload
                 max_retries=0  # Disable internal retries - handle retries at batch level
             )
-            logger.info(f"Ollama client created successfully with base URL: {clean_base_url}")
+            logger.info(f"Ollama client created with load-balanced instance: {best_instance.get('name')} ({clean_base_url})")
 
         elif provider_name == "google":
             if not api_key:
-- 
2.39.5

